{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calidad de datos anuales extraidos de NORTE LITORAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook se describen los procesos necesarios para comprobar la calidad de los datos anuales extraídos de la instancia de Microsoft SQL Server para Norte Litoral\n",
    "\n",
    "Es necesario hacer una validación de los datos antes de entrenar un modelo. La mayoría de los modelos entrenados son sensibles\n",
    "a valores incorrectos ( valores nulos, fallos de medición y/o otros problemas ). Estos valores pueden ser interpretados de manera incorrecta por el modelo.\n",
    "\n",
    "Proceso básico de validación de datos:\n",
    "\n",
    "- 1)  Test Valores Nulos - Comprobar que se dispone de datos para todas las fechas y segmentos\n",
    "        1.1) Comprobar que no hay nulos\n",
    "        1.2) Comprobar que se dispone del rango de fechas solicitado\n",
    "- 2)  Test Duplicados - Comprobar si existen filas duplicadas y quedarse con el primero\n",
    "- 4)  Test de Coherencia de Datos - Verificar que no existen saltos significativos entre intervalos consecutivos de datos\n",
    "        2.1) Calculo de autocorrelaciones parciales de datos \n",
    "        2.2) Establecimiento de un umbral significativo para descarte de datos \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cargando por Meses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enero = pd.read_csv('C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\monthly\\\\Datos_Anual\\\\01-18.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59540 entries, 0 to 59539\n",
      "Data columns (total 32 columns):\n",
      "ID_SEGMENTO           59540 non-null int64\n",
      "COD_LABORALIDAD       59540 non-null int64\n",
      "FECHA                 59540 non-null object\n",
      "MES                   59540 non-null int64\n",
      "HORA                  59540 non-null int64\n",
      "MINUTO                59540 non-null int64\n",
      "CANTIDAD_PREC         59540 non-null object\n",
      "TOTAL_VEHICULOS       59540 non-null int64\n",
      "TOTAL_VEHICULOS_1     59540 non-null int64\n",
      "TOTAL_VEHICULOS_2     59540 non-null int64\n",
      "TOTAL_VEHICULOS_3     59540 non-null int64\n",
      "TOTAL_VEHICULOS_4     59540 non-null int64\n",
      "TOTAL_VEHICULOS_5     59540 non-null int64\n",
      "TOTAL_VEHICULOS_6     59540 non-null int64\n",
      "TOTAL_VEHICULOS_7     59540 non-null int64\n",
      "TOTAL_VEHICULOS_8     59540 non-null int64\n",
      "TOTAL_VEHICULOS_9     59540 non-null int64\n",
      "TOTAL_VEHICULOS_10    59540 non-null int64\n",
      "TOTAL_VEHICULOS_11    59540 non-null int64\n",
      "TOTAL_VEHICULOS_12    59540 non-null int64\n",
      "TOTAL_VEHICULOS_13    59540 non-null int64\n",
      "TOTAL_VEHICULOS_14    59540 non-null int64\n",
      "TOTAL_VEHICULOS_15    59540 non-null int64\n",
      "TOTAL_VEHICULOS_16    59540 non-null int64\n",
      "TOTAL_VEHICULOS_17    59540 non-null int64\n",
      "TOTAL_VEHICULOS_18    59540 non-null int64\n",
      "TOTAL_VEHICULOS_19    59540 non-null int64\n",
      "TOTAL_VEHICULOS_20    59540 non-null int64\n",
      "TOTAL_VEHICULOS_21    59540 non-null int64\n",
      "TOTAL_VEHICULOS_22    59540 non-null int64\n",
      "TOTAL_VEHICULOS_23    59540 non-null int64\n",
      "TOTAL_VEHICULOS_24    59540 non-null int64\n",
      "dtypes: int64(30), object(2)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "enero.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Executing tests for Month: 1\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 2\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 3\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 4\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 5\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 6\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 7\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 8\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 9\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 10\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 11\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n",
      "----> Executing tests for Month: 12\n",
      "Test 0 - check that all segments are available\n",
      "All segments are available\n",
      "Test 1 - Missing values\n",
      "No missing values in the dataset\n",
      "Test 2 - Duplicates\n",
      "Saving results...\n"
     ]
    }
   ],
   "source": [
    "from calendar import monthrange\n",
    "\n",
    "for month_i in range(1,13):\n",
    "    print(\"----> Executing tests for Month: \" + str(month_i))\n",
    "    month = pd.read_csv('C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\monthly\\\\Datos_Anual\\\\' + \"{:02d}\".format(month_i) + '-18.csv', delimiter=\";\")\n",
    "\n",
    "    # Test 0 - check that all segments are available\n",
    "    print(\"Test 0 - check that all segments are available\")\n",
    "    if len(month.ID_SEGMENTO.unique()) == 20:\n",
    "        print(\"All segments are available\")\n",
    "\n",
    "    print(\"Test 1 - Missing values\")\n",
    "\n",
    "    for seg_i in enero.ID_SEGMENTO.unique():\n",
    "\n",
    "        month_seg = month.loc[month.ID_SEGMENTO == seg_i]\n",
    "        case_results = set()\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.day.unique()) == monthrange(2018, month_i)[1])\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.hour.unique()) == 24)\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.minute.unique()) == 60/15)\n",
    "\n",
    "    if case_results  == {True}:\n",
    "        print(\"No missing values in the dataset\")\n",
    "\n",
    "    print(\"Test 2 - Duplicates\")\n",
    "    case_results = set()\n",
    "    case_results.add(len(month.MES.unique()) == 1) \n",
    "    case_results.add(len(month[month.duplicated(['FECHA', 'ID_SEGMENTO'], keep='first')].index)==0)\n",
    "\n",
    "    if case_results  == {True}:\n",
    "        print(\"No duplicates values in the dataset\")\n",
    "    else: # Apply correction rules\n",
    "        month = month.loc[month.MES==month_i] # nos quedamos solo con el mes que queremos\n",
    "        month = month.drop_duplicates(['FECHA', 'ID_SEGMENTO'], keep='first')\n",
    "\n",
    "    print(\"Saving results...\")\n",
    "    month.to_csv('C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\datos_validados\\\\' + \"{:02d}\".format(month_i) + '-18.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pandas as pd\n",
    "findspark.init()\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = sqlContext.read.format(\"com.databricks.spark.csv\").options( header = True, inferSchema = True, sep=';',  line_terminator='\\n').load( path='C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\input.csv')\n",
    "df_anual_data = sqlContext.read.format(\"com.databricks.spark.csv\").options( header = True, sep=';',  line_terminator='\\n').schema(data_input.schema).load(\"C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\datos_validados\\\\*.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_anual_data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700800 entries, 0 to 700799\n",
      "Data columns (total 32 columns):\n",
      "ID_SEGMENT            691668 non-null float64\n",
      "COD_LABORALIDAD       691668 non-null float64\n",
      "FECHA                 691668 non-null datetime64[ns]\n",
      "MES                   691668 non-null float64\n",
      "HORA                  691668 non-null float64\n",
      "MINUTO                691668 non-null float64\n",
      "CANTIDAD_PREC         691668 non-null float64\n",
      "TOTAL_VEHICULOS       691668 non-null float64\n",
      "TOTAL_VEHICULOS_1     691668 non-null float64\n",
      "TOTAL_VEHICULOS_2     691668 non-null float64\n",
      "TOTAL_VEHICULOS_3     691668 non-null float64\n",
      "TOTAL_VEHICULOS_4     691668 non-null float64\n",
      "TOTAL_VEHICULOS_5     691668 non-null float64\n",
      "TOTAL_VEHICULOS_6     691668 non-null float64\n",
      "TOTAL_VEHICULOS_7     691668 non-null float64\n",
      "TOTAL_VEHICULOS_8     691668 non-null float64\n",
      "TOTAL_VEHICULOS_9     691668 non-null float64\n",
      "TOTAL_VEHICULOS_10    691668 non-null float64\n",
      "TOTAL_VEHICULOS_11    691668 non-null float64\n",
      "TOTAL_VEHICULOS_12    691668 non-null float64\n",
      "TOTAL_VEHICULOS_13    691668 non-null float64\n",
      "TOTAL_VEHICULOS_14    691668 non-null float64\n",
      "TOTAL_VEHICULOS_15    691668 non-null float64\n",
      "TOTAL_VEHICULOS_16    691668 non-null float64\n",
      "TOTAL_VEHICULOS_17    691668 non-null float64\n",
      "TOTAL_VEHICULOS_18    691668 non-null float64\n",
      "TOTAL_VEHICULOS_19    691668 non-null float64\n",
      "TOTAL_VEHICULOS_20    691668 non-null float64\n",
      "TOTAL_VEHICULOS_21    691668 non-null float64\n",
      "TOTAL_VEHICULOS_22    691668 non-null float64\n",
      "TOTAL_VEHICULOS_23    691668 non-null float64\n",
      "TOTAL_VEHICULOS_24    691668 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(31)\n",
      "memory usage: 171.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'ID_SEGMENT': 'ID_SEGMENTO'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Executing tests for Month: 1\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 2\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 3\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 4\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 5\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 6\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 7\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 8\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 9\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 10\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 11\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "----> Executing tests for Month: 12\n",
      "Test 0 - check that all segments are available\n",
      "Test 1 - Missing values\n",
      "Test 2 - Duplicates\n",
      "Executed all tests\n"
     ]
    }
   ],
   "source": [
    "for month_i in range(1,13):\n",
    "    print(\"----> Executing tests for Month: \" + str(month_i))\n",
    "    month = df.loc[df.ID_SEGMENTO == month_i]\n",
    "    \n",
    "    # Test 0 - check that all segments are available\n",
    "    print(\"Test 0 - check that all segments are available\")\n",
    "    if len(month.ID_SEGMENTO.unique()) == 20:\n",
    "        print(\"All segments are available\")\n",
    "\n",
    "    print(\"Test 1 - Missing values\")\n",
    "\n",
    "    for seg_i in enero.ID_SEGMENTO.unique():\n",
    "\n",
    "        month_seg = month.loc[month.ID_SEGMENTO == seg_i]\n",
    "        case_results = set()\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.day.unique()) == monthrange(2018, month_i)[1])\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.hour.unique()) == 24)\n",
    "        case_results.add(len(pd.to_datetime(month_seg.FECHA).dt.minute.unique()) == 60/15)\n",
    "\n",
    "    if case_results  == {True}:\n",
    "        print(\"No missing values in the dataset\")\n",
    "\n",
    "    print(\"Test 2 - Duplicates\")\n",
    "    case_results = set()\n",
    "    case_results.add(len(month.MES.unique()) == 1) \n",
    "    case_results.add(len(month[month.duplicated(['FECHA', 'ID_SEGMENTO'], keep='first')].index)==0)\n",
    "\n",
    "    if case_results  == {True}:\n",
    "        print(\"No duplicates values in the dataset\")\n",
    "    else: # Apply correction rules\n",
    "        month = month.loc[month.MES==month_i] # nos quedamos solo con el mes que queremos\n",
    "        month = month.drop_duplicates(['FECHA', 'ID_SEGMENTO'], keep='first')\n",
    "\n",
    "print(\"Executed all tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\datos_validados\\\\anual_data_18.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1)  Test Valores Nulos - Comprobar que se dispone de datos para todas las fechas y segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yhoz\\.conda\\envs\\predictive.analytics\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (0,1,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "anual_data = pd.read_csv('C:\\\\Users\\\\yhoz\\\\Documents\\\\dataanalytics.predictive\\\\data\\\\datos_2018_gen_modelos\\\\anual_data_2018.csv', delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 701045 entries, 0 to 701044\n",
      "Data columns (total 32 columns):\n",
      "ID_SEGMENTO           701045 non-null object\n",
      "COD_LABORALIDAD       701045 non-null object\n",
      "FECHA                 701045 non-null object\n",
      "MES                   701045 non-null object\n",
      "HORA                  701045 non-null object\n",
      "MINUTO                701045 non-null object\n",
      "CANTIDAD_PREC         701045 non-null object\n",
      "TOTAL_VEHICULOS       701045 non-null object\n",
      "TOTAL_VEHICULOS_1     701045 non-null object\n",
      "TOTAL_VEHICULOS_2     701045 non-null object\n",
      "TOTAL_VEHICULOS_3     701045 non-null object\n",
      "TOTAL_VEHICULOS_4     701045 non-null object\n",
      "TOTAL_VEHICULOS_5     701045 non-null object\n",
      "TOTAL_VEHICULOS_6     701045 non-null object\n",
      "TOTAL_VEHICULOS_7     701045 non-null object\n",
      "TOTAL_VEHICULOS_8     701045 non-null object\n",
      "TOTAL_VEHICULOS_9     701045 non-null object\n",
      "TOTAL_VEHICULOS_10    701045 non-null object\n",
      "TOTAL_VEHICULOS_11    701045 non-null object\n",
      "TOTAL_VEHICULOS_12    701045 non-null object\n",
      "TOTAL_VEHICULOS_13    701045 non-null object\n",
      "TOTAL_VEHICULOS_14    701045 non-null object\n",
      "TOTAL_VEHICULOS_15    701045 non-null object\n",
      "TOTAL_VEHICULOS_16    701045 non-null object\n",
      "TOTAL_VEHICULOS_17    701045 non-null object\n",
      "TOTAL_VEHICULOS_18    701045 non-null object\n",
      "TOTAL_VEHICULOS_19    701045 non-null object\n",
      "TOTAL_VEHICULOS_20    701045 non-null object\n",
      "TOTAL_VEHICULOS_21    701045 non-null object\n",
      "TOTAL_VEHICULOS_22    701045 non-null object\n",
      "TOTAL_VEHICULOS_23    701045 non-null object\n",
      "TOTAL_VEHICULOS_24    701045 non-null object\n",
      "dtypes: object(32)\n",
      "memory usage: 171.2+ MB\n"
     ]
    }
   ],
   "source": [
    "anual_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID_SEGMENTO           False\n",
       "COD_LABORALIDAD       False\n",
       "FECHA                 False\n",
       "MES                   False\n",
       "HORA                  False\n",
       "MINUTO                False\n",
       "CANTIDAD_PREC         False\n",
       "TOTAL_VEHICULOS       False\n",
       "TOTAL_VEHICULOS_1     False\n",
       "TOTAL_VEHICULOS_2     False\n",
       "TOTAL_VEHICULOS_3     False\n",
       "TOTAL_VEHICULOS_4     False\n",
       "TOTAL_VEHICULOS_5     False\n",
       "TOTAL_VEHICULOS_6     False\n",
       "TOTAL_VEHICULOS_7     False\n",
       "TOTAL_VEHICULOS_8     False\n",
       "TOTAL_VEHICULOS_9     False\n",
       "TOTAL_VEHICULOS_10    False\n",
       "TOTAL_VEHICULOS_11    False\n",
       "TOTAL_VEHICULOS_12    False\n",
       "TOTAL_VEHICULOS_13    False\n",
       "TOTAL_VEHICULOS_14    False\n",
       "TOTAL_VEHICULOS_15    False\n",
       "TOTAL_VEHICULOS_16    False\n",
       "TOTAL_VEHICULOS_17    False\n",
       "TOTAL_VEHICULOS_18    False\n",
       "TOTAL_VEHICULOS_19    False\n",
       "TOTAL_VEHICULOS_20    False\n",
       "TOTAL_VEHICULOS_21    False\n",
       "TOTAL_VEHICULOS_22    False\n",
       "TOTAL_VEHICULOS_23    False\n",
       "TOTAL_VEHICULOS_24    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anual_data.isnull().any() # sum() to count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700800.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aproximacion estimada del numero de filas que deberia contener el dataset\n",
    "365*24*(60/15)*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = anual_data[anual_data.duplicated(['FECHA', 'ID_SEGMENTO'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 179 entries, 113321 to 641524\n",
      "Data columns (total 32 columns):\n",
      "ID_SEGMENTO           179 non-null object\n",
      "COD_LABORALIDAD       179 non-null object\n",
      "FECHA                 179 non-null object\n",
      "MES                   179 non-null object\n",
      "HORA                  179 non-null object\n",
      "MINUTO                179 non-null object\n",
      "CANTIDAD_PREC         179 non-null object\n",
      "TOTAL_VEHICULOS       179 non-null object\n",
      "TOTAL_VEHICULOS_1     179 non-null object\n",
      "TOTAL_VEHICULOS_2     179 non-null object\n",
      "TOTAL_VEHICULOS_3     179 non-null object\n",
      "TOTAL_VEHICULOS_4     179 non-null object\n",
      "TOTAL_VEHICULOS_5     179 non-null object\n",
      "TOTAL_VEHICULOS_6     179 non-null object\n",
      "TOTAL_VEHICULOS_7     179 non-null object\n",
      "TOTAL_VEHICULOS_8     179 non-null object\n",
      "TOTAL_VEHICULOS_9     179 non-null object\n",
      "TOTAL_VEHICULOS_10    179 non-null object\n",
      "TOTAL_VEHICULOS_11    179 non-null object\n",
      "TOTAL_VEHICULOS_12    179 non-null object\n",
      "TOTAL_VEHICULOS_13    179 non-null object\n",
      "TOTAL_VEHICULOS_14    179 non-null object\n",
      "TOTAL_VEHICULOS_15    179 non-null object\n",
      "TOTAL_VEHICULOS_16    179 non-null object\n",
      "TOTAL_VEHICULOS_17    179 non-null object\n",
      "TOTAL_VEHICULOS_18    179 non-null object\n",
      "TOTAL_VEHICULOS_19    179 non-null object\n",
      "TOTAL_VEHICULOS_20    179 non-null object\n",
      "TOTAL_VEHICULOS_21    179 non-null object\n",
      "TOTAL_VEHICULOS_22    179 non-null object\n",
      "TOTAL_VEHICULOS_23    179 non-null object\n",
      "TOTAL_VEHICULOS_24    179 non-null object\n",
      "dtypes: object(32)\n",
      "memory usage: 46.1+ KB\n"
     ]
    }
   ],
   "source": [
    "duplicates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "anual_data_no_duplicates = anual_data.drop_duplicates(['FECHA', 'ID_SEGMENTO'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 700866 entries, 0 to 701044\n",
      "Data columns (total 32 columns):\n",
      "ID_SEGMENTO           700866 non-null object\n",
      "COD_LABORALIDAD       700866 non-null object\n",
      "FECHA                 700866 non-null object\n",
      "MES                   700866 non-null object\n",
      "HORA                  700866 non-null object\n",
      "MINUTO                700866 non-null object\n",
      "CANTIDAD_PREC         700866 non-null object\n",
      "TOTAL_VEHICULOS       700866 non-null object\n",
      "TOTAL_VEHICULOS_1     700866 non-null object\n",
      "TOTAL_VEHICULOS_2     700866 non-null object\n",
      "TOTAL_VEHICULOS_3     700866 non-null object\n",
      "TOTAL_VEHICULOS_4     700866 non-null object\n",
      "TOTAL_VEHICULOS_5     700866 non-null object\n",
      "TOTAL_VEHICULOS_6     700866 non-null object\n",
      "TOTAL_VEHICULOS_7     700866 non-null object\n",
      "TOTAL_VEHICULOS_8     700866 non-null object\n",
      "TOTAL_VEHICULOS_9     700866 non-null object\n",
      "TOTAL_VEHICULOS_10    700866 non-null object\n",
      "TOTAL_VEHICULOS_11    700866 non-null object\n",
      "TOTAL_VEHICULOS_12    700866 non-null object\n",
      "TOTAL_VEHICULOS_13    700866 non-null object\n",
      "TOTAL_VEHICULOS_14    700866 non-null object\n",
      "TOTAL_VEHICULOS_15    700866 non-null object\n",
      "TOTAL_VEHICULOS_16    700866 non-null object\n",
      "TOTAL_VEHICULOS_17    700866 non-null object\n",
      "TOTAL_VEHICULOS_18    700866 non-null object\n",
      "TOTAL_VEHICULOS_19    700866 non-null object\n",
      "TOTAL_VEHICULOS_20    700866 non-null object\n",
      "TOTAL_VEHICULOS_21    700866 non-null object\n",
      "TOTAL_VEHICULOS_22    700866 non-null object\n",
      "TOTAL_VEHICULOS_23    700866 non-null object\n",
      "TOTAL_VEHICULOS_24    700866 non-null object\n",
      "dtypes: object(32)\n",
      "memory usage: 176.5+ MB\n"
     ]
    }
   ],
   "source": [
    "anual_data_no_duplicates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "700866 + 179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) Comprobar que se dispone del rango de fechas solicitado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, '1', 'MES', '2', '3', 3, '4', 4, '5', 5, '6', 6, 7, 8, 9, 10,\n",
       "       11, 12], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anual_data_no_duplicates.MES.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
